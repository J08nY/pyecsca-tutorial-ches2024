{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c1a77dda-b8f2-4812-b5a6-001206de9f1d",
   "metadata": {},
   "source": [
    "# Implementations\n",
    "\n",
    "This notebook delves into the world of ECC implementations.\n",
    "\n",
    " - You will first [analyze traces](#Manual-analysis) collected from a Curve25519 implementation to learn information about the implementation.\n",
    "    - How many iterations are in the scalar multiplier?\n",
    "    - Is the scalar multiplier left-to-right or right-to-left?\n",
    " - Then you will explore the number of ECC implementations [combinatorially](#Implementation-space)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0492407-4c2f-456d-8be4-411f378ec272",
   "metadata": {},
   "source": [
    "## Manual analysis\n",
    "\n",
    "[sca25519](https://github.com/sca-secure-library-sca25519/sca25519) is an open-source implementation of the Curve25519 key-exchange (XDH) for the ARM Cortex-M4. It contains three **implementations**:\n",
    "\n",
    " - unprotected\n",
    " - ephemeral\n",
    " - static\n",
    "\n",
    "that contain different countermeasures, with the unprotected one being free of any.\n",
    "\n",
    "You will work with three trace sets of scalar multiplication:\n",
    " - **A**: [Download](https://neuromancer.sk/static/traces_A.pickle) Traces of the full scalar multiplication. 10 traces per implementation: all implementations. Fixed scalar and point.\n",
    " - **B**: [Download](https://neuromancer.sk/static/traces_B.pickle) Traces of the beginning of the scalar multiplication. 1000 traces. Unprotected implementation. Random scalar.\n",
    " - **C**: [Download](https://neuromancer.sk/static/traces_C.pickle) Traces of the end of the scalar multiplication. 1000 traces. Unprotected implementation. Random scalar. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fdf256f-ed10-42fe-934d-19d9462e1e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyecsca.sca.trace_set import PickleTraceSet, HDF5TraceSet\n",
    "from pyecsca.sca.trace import Trace\n",
    "from pyecsca.sca.trace.plot import plot_trace, plot_traces\n",
    "from pyecsca.ec.params import get_params\n",
    "from pyecsca.ec.point import Point\n",
    "from pyecsca.ec.mod import Mod\n",
    "\n",
    "import holoviews as hv\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3431cbae-e144-48d4-ac6d-5cd81803b565",
   "metadata": {},
   "outputs": [],
   "source": [
    "hv.extension(\"bokeh\")\n",
    "%opts RGB [height=600, responsive=True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d692b600-d137-45be-a108-ef44ceba0d90",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "curve25519 = get_params(\"other\", \"Curve25519\", \"xz\")\n",
    "p = curve25519.curve.prime\n",
    "n = curve25519.order"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b6debfe-7f14-4a71-ba15-3661deadcb58",
   "metadata": {},
   "source": [
    "### <span style=\"color:#00468C; font-weight: bold;\">Exercise</span>\n",
    "\n",
    "Use trace set **A** and visually analyze the traces:\n",
    "\n",
    " - Plot them.\n",
    " - Compare them between implementations.\n",
    " - Process them using e.g. rolling mean and count peaks on them.\n",
    " - How many iterations does the scalar multiplier have in the unprotected case?\n",
    "\n",
    "**Docs**<br/>\n",
    "[plot module](https://neuromancer.sk/pyecsca/api/pyecsca.sca.trace.plot.html)<br/>\n",
    "[scipy.signal.find_peaks](https://docs.scipy.org/doc/scipy/reference/generated/scipy.signal.find_peaks.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f102fcc5-7336-4b62-8885-6eea814ea01b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyecsca.sca.trace.plot import plot_trace, plot_traces\n",
    "from pyecsca.sca.trace.process import rolling_mean\n",
    "from scipy.signal import find_peaks\n",
    "\n",
    "def plot_trace_peaks(peaks, trace):\n",
    "    return plot_trace(trace) * hv.Points((peaks, trace.samples[peaks])).opts(color=\"red\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8cd0750-0d36-4f39-b1d5-f8e784d4aaad",
   "metadata": {},
   "outputs": [],
   "source": [
    "traces_A = PickleTraceSet.read(\"../traces_A.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51733225-70a0-4de3-91c6-50ee7fe08423",
   "metadata": {},
   "outputs": [],
   "source": [
    "traces_A[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84a0ef7c-de81-4eba-9202-88fee88a009b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task: Plot two traces from the unprotected implementation.\n",
    "# Hint: Look at the .meta attribute of the traces.\n",
    "plot_traces(traces_A[0], traces_A[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be5313a1-bb2f-468b-b444-6118072e4b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task: Plot traces from the other implementations.\n",
    "plot_traces(traces_A[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c366616d-beda-43ff-afcd-3b937069a6a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_traces(traces_A[20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "253fa06d-5dda-4ba9-9f14-062988f07d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task: Use rolling_mean and find_peaks to count the iterations in the unprotected implementation\n",
    "# Note: Before applying the rolling mean, make sure to transform the dtype of the trace by doing trace.astype(np.float32) and using the result.\n",
    "# Hint: You can use plot_trace_peaks to plot the trace along with the detected peaks from find_peaks.\n",
    "meany = rolling_mean(traces_A[0].astype(np.float32), 5000)\n",
    "peaks, other = find_peaks(meany.samples, height=10, distance=5000)\n",
    "print(len(peaks))\n",
    "plot_trace_peaks(peaks, meany)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d09508f8-4cc2-4c78-b302-dc6a711f71b3",
   "metadata": {},
   "source": [
    "### <span style=\"color:#00468C; font-weight: bold;\">Exercise</span>\n",
    "\n",
    "Use trace set **B** and correlate the most significant bits of the scalar with the trace set.\n",
    "\n",
    " - Is the multiplier left-to-right or right-to-left?\n",
    "\n",
    "> Note: The correlation computation takes a fair bit of memory (4-8GB), make sure you have it. **This will likely not work on myBinder.**\n",
    "\n",
    "\n",
    "**Docs**<br/>\n",
    "[StackedTraces](https://neuromancer.sk/pyecsca/api/pyecsca.sca.stacked_traces.stacked_traces.html#pyecsca.sca.stacked_traces.stacked_traces.StackedTraces)<br/>\n",
    "[CPUTraceManager.pearson_corr](https://neuromancer.sk/pyecsca/api/pyecsca.sca.stacked_traces.combine.html#pyecsca.sca.stacked_traces.combine.CPUTraceManager.pearson_corr)<br/>\n",
    "[Leakage models, Hamming Weight, Bit](https://neuromancer.sk/pyecsca/api/pyecsca.sca.attack.leakage_model.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea912e4a-285f-47bb-8f44-eb5e721f3070",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyecsca.sca.stacked_traces import StackedTraces, CPUTraceManager\n",
    "from pyecsca.sca.attack.leakage_model import HammingWeight, Bit\n",
    "from pyecsca.sca.trace.plot import plot_trace, plot_traces\n",
    "from pyecsca.sca.trace.process import normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9c9180c-dcf0-4d7a-b57c-42c3750238e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "traces_B = PickleTraceSet.read(\"../traces_B.pickle\")\n",
    "traces_C = PickleTraceSet.read(\"../traces_C.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61724a6e-3900-473d-9866-ffb71a4a2921",
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked_B = StackedTraces.fromtraceset(traces_B)\n",
    "mng_B = CPUTraceManager(stacked_B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c48509a-ad54-44c8-860e-ce377bfc1956",
   "metadata": {},
   "outputs": [],
   "source": [
    "corrs = []\n",
    "for i in (253, 252, 251):\n",
    "    lm = Bit(i)\n",
    "    ivs = np.array(list(map(lambda t: lm(t.meta[\"scalar\"]), traces_B)))\n",
    "    corrs.append(normalize(Trace(mng_B.pearson_corr(ivs))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba6c9e3c-e8e7-4de4-a6df-f6f535e88b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_traces(rolling_mean(corrs[0], 7000), rolling_mean(corrs[1], 7000), rolling_mean(corrs[2], 7000))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbaf9c30-9528-47c4-9894-61e6cfb019ba",
   "metadata": {},
   "source": [
    "### <span style=\"color:#00468C; font-weight: bold;\">Exercise</span>\n",
    "\n",
    "Use trace set **C** and correlate Hamming Weights of a few bytes of the result of the scalar multiplication with the traces.\n",
    "\n",
    " - Where do you see correlation? What does it mean? Does it happen during the scalar multiplication?\n",
    "\n",
    "This trace set comes from the same set as trace **B** but we aligned the traces at the end for you so you are able to detect the result leakage using correlation. \n",
    "\n",
    "**Docs**<br/>\n",
    "[StackedTraces](https://neuromancer.sk/pyecsca/api/pyecsca.sca.stacked_traces.stacked_traces.html#pyecsca.sca.stacked_traces.stacked_traces.StackedTraces)<br/>\n",
    "[CPUTraceManager.pearson_corr](https://neuromancer.sk/pyecsca/api/pyecsca.sca.stacked_traces.combine.html#pyecsca.sca.stacked_traces.combine.CPUTraceManager.pearson_corr)<br/>\n",
    "[Leakage models, Hamming Weight, Bit](https://neuromancer.sk/pyecsca/api/pyecsca.sca.attack.leakage_model.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f47318cf-0320-4586-8a66-bea3d05a2053",
   "metadata": {},
   "outputs": [],
   "source": [
    "#In the original traces correlate the traces with the hamming wieght of data at index 70\n",
    "#In your traces it will be HW of one byte of the point\n",
    "HW = [bin(n).count(\"1\") for n in range(0, 256)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60dbf191-4e39-4dac-a5b1-d939466acccb",
   "metadata": {},
   "source": [
    "### <span style=\"color:#00468C; font-weight: bold;\">Exercise</span>\n",
    "\n",
    "Use trace set **B** and to perform a CPA-like attack on first 1000 traces. \n",
    "\n",
    "Let's veryify that the traces corresponds to X25519 where the most significant bit is always 1. \n",
    "\n",
    "**Docs**<br/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63404b7e-0204-45bd-acc2-f2e87e2ad9b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ECC code:\n",
    "curve25519_P = 2 ** 255 - 19\n",
    "curve25519_A = 486662\n",
    "# from https://gist.github.com/nickovs/cc3c22d15f239a2640c185035c06f8a3\n",
    "def _point_add(point_n, point_m, point_diff):\n",
    "    \"\"\"Given the projection of two points and their difference, return their sum\"\"\"\n",
    "    (xn, zn) = point_n\n",
    "    (xm, zm) = point_m\n",
    "    (x_diff, z_diff) = point_diff\n",
    "    x = (z_diff << 2) * (xm * xn - zm * zn) ** 2\n",
    "    z = (x_diff << 2) * (xm * zn - zm * xn) ** 2\n",
    "    return x % curve25519_P, z % curve25519_P\n",
    "\n",
    "# from https://gist.github.com/nickovs/cc3c22d15f239a2640c185035c06f8a3\n",
    "def _point_double(point_n):\n",
    "    \"\"\"Double a point provided in projective coordinates\"\"\"\n",
    "    (xn, zn) = point_n\n",
    "    xn2 = xn ** 2\n",
    "    zn2 = zn ** 2\n",
    "    x = (xn2 - zn2) ** 2\n",
    "    xzn = xn * zn\n",
    "    z = 4 * xzn * (xn2 + curve25519_A * xzn + zn2)\n",
    "    return x % curve25519_P, z % curve25519_P\n",
    "\n",
    "\n",
    "# from https://gist.github.com/nickovs/cc3c22d15f239a2640c185035c06f8a3\n",
    "def _const_time_swap(a, b, swap):\n",
    "    \"\"\"Swap two values in constant time\"\"\"\n",
    "    index = int(swap) * 2\n",
    "    temp = (a, b, b, a)\n",
    "    return temp[index:index+2]\n",
    "\n",
    "\n",
    "# from https://gist.github.com/nickovs/cc3c22d15f239a2640c185035c06f8a3\n",
    "def _raw_curve25519(base, n):\n",
    "    \"\"\"Raise the point base to the power n\"\"\"\n",
    "    zero = (1, 0)\n",
    "    one = (base, 1)\n",
    "    mP, m1P = zero, one\n",
    "\n",
    "    for i in reversed(range(256)):\n",
    "        bit = bool(n & (1 << i))\n",
    "        mP, m1P = _const_time_swap(mP, m1P, bit)\n",
    "\n",
    "        if i >= 247:\n",
    "            print(\"x1: \", hex(mP[0]))\n",
    "            print(\"z1: \", hex(mP[1]))\n",
    "            print(\"x2: \", hex(m1P[0]))\n",
    "            print(\"z2: \", hex(m1P[1]))\n",
    "            print(\"--------------------\")\n",
    "\n",
    "        mP, m1P = _point_double(mP), _point_add(mP, m1P, one)\n",
    "        mP, m1P = _const_time_swap(mP, m1P, bit)\n",
    "\n",
    "    x, z = mP\n",
    "    x1, z1 = m1P\n",
    "    #inv_z = pow(z, curve25519_P - 2, curve25519_P)\n",
    "    #return (x * inv_z) % curve25519_P\n",
    "    return x, z, x1, z1\n",
    "\n",
    "# function taken from https://github.com/lhrbacek/ed25519-py/blob/main/curve25519.py\n",
    "# from https://gist.github.com/nickovs/cc3c22d15f239a2640c185035c06f8a3\n",
    "# base - x coordinate of point as bytearray/bytes in big endian (msb on left)\n",
    "# n - scalar\n",
    "#\n",
    "# Usage:\n",
    "#    point = bytearray(bytes.fromhex('010203'))\n",
    "#    g = scamult_once_curve25519(point, 1)\n",
    "#    print(hex(g))\n",
    "#\n",
    "def scamult_once_curve25519(base, n):\n",
    "    \"\"\"Raise the point base to the power n, return x of mP without conoversion back to affine\"\"\"\n",
    "    Px = int.from_bytes(base, byteorder='little')\n",
    "    zero = (1, 0)\n",
    "    one = (Px, 1)\n",
    "    mP, m1P = zero, one\n",
    "\n",
    "    for i in reversed(range(1)):\n",
    "        bit = bool(n & (1 << i))\n",
    "        mP, m1P = _const_time_swap(mP, m1P, bit)\n",
    "        mP, m1P = _point_double(mP), _point_add(mP, m1P, one)\n",
    "        mP, m1P = _const_time_swap(mP, m1P, bit)\n",
    "\n",
    "    x, z = mP\n",
    "    x1, z1 = m1P\n",
    "    #inv_z = pow(z, curve25519_P - 2, curve25519_P)\n",
    "    #return (x * inv_z) % curve25519_P\n",
    "    return x\n",
    "\n",
    "hex_string = \"a9849099874a6df03299eb341e7fd9be4d8e922ecf5d039a01d534c505b36483\"\n",
    "bytes_result = bytearray.fromhex(hex_string)\n",
    "print(bytes_result)\n",
    "\n",
    "point = bytearray(bytes.fromhex(hex_string))\n",
    "point[31]=point[31]&0x7F\n",
    "g = scamult_once_curve25519(point, 1)\n",
    "print(hex(g))\n",
    "byte_representation = g.to_bytes(32, byteorder='big')\n",
    "print(''.join(format(x, '02x') for x in byte_representation))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15a77ef6-12ec-4497-8c98-7a3fb32b1bb2",
   "metadata": {},
   "source": [
    "## Implementation space\n",
    "Let's explore the space of ECC implementations and examine how large and diverse it is. Recall the slide about real-world ECC implementations in open-source libraries and how varied those were. Now, we can use **pyecsca** to enumerate ECC implementation configurations.\n",
    "\n",
    "> Note: These cells are prepared for you, you do not need to implement anything."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "378009d5-c70c-4428-9d3f-c6bec9a2f828",
   "metadata": {},
   "source": [
    "An ECC implementation configuration in **pyecsca** has the following attributes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c65da0a1-7197-4ffc-97c5-cf379f0e5103",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from typing import get_args\n",
    "from IPython.display import display, HTML\n",
    "from pyecsca.ec.configuration import Configuration\n",
    "from dataclasses import fields\n",
    "\n",
    "content = \"\"\n",
    "for field in fields(Configuration):\n",
    "    name = field.name\n",
    "    tp = field.type\n",
    "    doc = tp.__doc__\n",
    "    if get_args(field.type):\n",
    "            doc = get_args(field.type)[0].__doc__\n",
    "    tn = repr(tp) if tp.__module__ == \"typing\" else f\"{tp.__module__}.{tp.__name__}\"\n",
    "    entry = \"\"\n",
    "    entry += f\"<b>{name}</b> <code>{tn}</code><br/>\"\n",
    "    entry += f\"<pre>{doc}</pre><br/>\"\n",
    "    if hasattr(tp, \"names\"):\n",
    "        for enum_name in tp.names():\n",
    "            entry += f\"{enum_name}<br/>\"\n",
    "    content += f\"<li>{entry}</li>\"\n",
    "display(HTML(f\"<ul>{content}</ul>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f92e414-6110-4483-93fb-b6f1c2bfb494",
   "metadata": {},
   "source": [
    "The possible configurations can be generated using the `all_configurations()` function. The whole space of configurations is quite huge, so we will not enumerate them.\n",
    "\n",
    "A large part of the configuration space is due to the independent options which consist of:\n",
    " \n",
    " - `hash_type` of type `HashType` $*6$\n",
    " - `mod_rand` of type `RandomMod` $*2$\n",
    " - `mult` of type `Multiplication` $*4$\n",
    " - `sqr` of type `Squaring` $*4$\n",
    " - `red` of type `Reduction` $*3$\n",
    " - `inv` of type `Inversion` $*2$\n",
    "\n",
    "Without these, the space is somewhat smaller.\n",
    "\n",
    "To restrict the generated configurations, pass keyword arguments to the\n",
    "`all_configurations` matching the names of the attributes of the `Configuration` object.\n",
    "\n",
    "Below, we look at how many configurations there are for projective coordinates on short-Weierstrass curves using\n",
    "the left-to-right double-and-add scalar multiplier (which has several parametrizations itself)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28f14b0c-25d4-4149-98d6-a32ab8ee1857",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyecsca.ec.configuration import all_configurations, HashType, RandomMod, Multiplication, Squaring, Reduction, Inversion\n",
    "from pyecsca.ec.model import ShortWeierstrassModel\n",
    "from pyecsca.ec.mult import LTRMultiplier\n",
    "\n",
    "model = ShortWeierstrassModel()\n",
    "coords = model.coordinates[\"projective\"]\n",
    "scalarmult = LTRMultiplier\n",
    "independent_opts = {\n",
    "    \"hash_type\": HashType.SHA256,\n",
    "    \"mod_rand\": RandomMod.SAMPLE,\n",
    "    \"mult\": Multiplication.KARATSUBA,\n",
    "    \"sqr\": Squaring.KARATSUBA,\n",
    "    \"red\": Reduction.MONTGOMERY,\n",
    "    \"inv\": Inversion.GCD\n",
    "}\n",
    "\n",
    "configs = list(all_configurations(model=model, coords=coords, scalarmult=scalarmult,\n",
    "                                                              **independent_opts))\n",
    "print(len(configs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9680c235-b8e4-49c7-9b8e-6959a6813e24",
   "metadata": {},
   "source": [
    "We see that when we fixed all parameters except for the scalar multiplier arguments \n",
    "(see the `LTRMultiplier` constructor) we obtained 1280 configurations. That number expresses all of the possible ways to use addition formulas for the `projective` coordinate system in the binary left-to-right multiplier as well as internal options of that multiplier:\n",
    "\n",
    " - whether it is \"complete\" in a sense that it starts processing at a constant bit (the bit-length od the order)\n",
    " - whether it is \"double-and-add-always\"\n",
    " - whether it \"short-circuits\" the formulas, i.e. detects that an exceptional point was input into them and returns correctly\n",
    "   without executing them.\n",
    "\n",
    "If we also restrict the formulas to concrete ones, we just get the variants of the scalar multiplier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51767df4-07b1-45f3-81c2-e088af56d64e",
   "metadata": {},
   "outputs": [],
   "source": [
    "formulas = {coords.formulas[\"add-2007-bl\"], coords.formulas[\"dbl-2007-bl\"]}\n",
    "\n",
    "configs = list(filter(lambda cfg: set(cfg.scalarmult.formulas.values()) == formulas, configs))\n",
    "print(len(configs))\n",
    "for cfg in configs:\n",
    "    print(str(cfg.scalarmult), \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b78b7ee7-a456-4bd3-b54c-96ccf4d951f0",
   "metadata": {},
   "source": [
    "### Models\n",
    "We can explore the number of configurations for each of the supported curve models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c343535-b19d-4386-b245-bc2ad2c41abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML, display\n",
    "import tabulate\n",
    "from pyecsca.ec.model import *\n",
    "from pyecsca.ec.mult import ProcessingDirection, AccumulationOrder\n",
    "\n",
    "no_indep = (6*2*4*4*3*2)\n",
    "no_ff = (6*2)\n",
    "\n",
    "model_counts = [[\"Model\", \"All\", \"Without independent options\", \"Without independent options and scaling\", \"Without independent options and scalarmult options\"]]\n",
    "totals = [\"Total\", 0, 0, 0, 0]\n",
    "for model in (ShortWeierstrassModel(), MontgomeryModel(), EdwardsModel(), TwistedEdwardsModel()):\n",
    "    name = model.__class__.__name__\n",
    "    count = sum(1 for _ in all_configurations(model=model, **independent_opts))\n",
    "    count_no_scl = sum(1 for _ in all_configurations(model=model, **independent_opts, scalarmult={\"scl\": None}))\n",
    "    count_no_opts = sum(1 for _ in all_configurations(model=model, **independent_opts, scalarmult={\"scl\": None, \"always\": True, \"short_circuit\": True, \"complete\": False, \"precompute_negation\": True, \"width\": 3, \"m\": 3, \"direction\": ProcessingDirection.LTR, \"accumulation_order\": AccumulationOrder.PeqPR, \"recoding_direction\": ProcessingDirection.LTR}))\n",
    "    model_counts.append([name, count * no_ff, count, count_no_scl, count_no_opts])\n",
    "    totals[1] += count * no_ff\n",
    "    totals[2] += count\n",
    "    totals[3] += count_no_scl\n",
    "    totals[4] += count_no_opts\n",
    "model_counts.append(totals)\n",
    "display(HTML(tabulate.tabulate(model_counts, tablefmt=\"html\", headers=\"firstrow\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "293734fa-6f29-45fa-b932-4b6258308cd0",
   "metadata": {},
   "source": [
    "### Coordinate models\n",
    "\n",
    "Let's now look at the configuration split for coordinate systems:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ab57486-91c4-460c-84df-cbcd48e0088a",
   "metadata": {},
   "outputs": [],
   "source": [
    "coords_counts = [[\"Model\", \"Coords\", \"All\", \"Without independent options\", \"Without independent options and scaling\", \"Without independent options and scalarmult options\"]]\n",
    "for model in (ShortWeierstrassModel(), MontgomeryModel(), EdwardsModel(), TwistedEdwardsModel()):\n",
    "    model_name = model.__class__.__name__\n",
    "    coords_counts.append([model_name, \"\", \"\", \"\", \"\", \"\"])\n",
    "    for coords in sorted(model.coordinates.values(), key=lambda c: c.name):\n",
    "            coords_name = coords.name\n",
    "            count = sum(1 for _ in all_configurations(model=model, coords=coords, **independent_opts))\n",
    "            count_no_scl = sum(1 for _ in all_configurations(model=model, coords=coords, **independent_opts, scalarmult={\"scl\": None}))\n",
    "            count_no_opts = sum(1 for _ in all_configurations(model=model, coords=coords, **independent_opts, scalarmult={\"scl\": None, \"always\": True, \"short_circuit\": True, \"complete\": False, \"precompute_negation\": True, \"width\": 3, \"m\": 3, \"direction\": ProcessingDirection.LTR, \"accumulation_order\": AccumulationOrder.PeqPR, \"recoding_direction\": ProcessingDirection.LTR}))\n",
    "            coords_counts.append([\"\", coords_name, count * no_ff, count, count_no_scl, count_no_opts])\n",
    "\n",
    "display(HTML(tabulate.tabulate(coords_counts, tablefmt=\"html\", headers=\"firstrow\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81bc86bd-36f3-40ca-a538-43b6b7dce668",
   "metadata": {},
   "source": [
    "### Scalar multipliers\n",
    "\n",
    "Finally, lets look at how the configurations look from the perspective of scalar multipliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2920d122-6a03-42a6-87b8-f75de572d932",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyecsca.ec.mult import ScalarMultiplier\n",
    "\n",
    "def leaf_subclasses(cls):\n",
    "    subs = cls.__subclasses__()\n",
    "    result = set()\n",
    "    for subclass in subs:\n",
    "        if subclass.__subclasses__():\n",
    "            result.update(leaf_subclasses(subclass))\n",
    "        else:\n",
    "            result.add(subclass)\n",
    "    return result\n",
    "\n",
    "mult_counts = [[\"ScalarMultiplier\", \"All\", \"Without independent options\", \"Without independent options and scaling\", \"Without independent options and scalarmult options\"]]\n",
    "for mult_cls in leaf_subclasses(ScalarMultiplier):\n",
    "    count = sum(1 for _ in all_configurations(**independent_opts, scalarmult=mult_cls))\n",
    "    count_no_scl = sum(1 for _ in all_configurations(**independent_opts, scalarmult={\"cls\": mult_cls, \"scl\": None}))\n",
    "    count_no_opts = sum(1 for _ in all_configurations(**independent_opts, scalarmult={\"cls\": mult_cls, \"scl\": None, \"always\": True, \"short_circuit\": True, \"complete\": False, \"precompute_negation\": True, \"width\": 3, \"m\": 3, \"direction\": ProcessingDirection.LTR, \"accumulation_order\": AccumulationOrder.PeqPR, \"recoding_direction\": ProcessingDirection.LTR}))\n",
    "    mult_counts.append([mult_cls.__name__, count * no_ff, count, count_no_scl, count_no_opts])\n",
    "\n",
    "display(HTML(tabulate.tabulate(mult_counts, tablefmt=\"html\", headers=\"firstrow\")))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
